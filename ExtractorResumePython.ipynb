{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdfium2 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (4.30.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: backoff in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (11.1.0)\n",
      "Requirement already satisfied: python-docx in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (1.1.2)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (20240706)\n",
      "Requirement already satisfied: spacy in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (3.8.4)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from python-docx->-r requirements.txt (line 4)) (5.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from python-docx->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from pdfminer.six->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from pdfminer.six->-r requirements.txt (line 5)) (44.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (57.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six->-r requirements.txt (line 5)) (1.17.1)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 6)) (2.27.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 6)) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 6)) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6)) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6)) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from jinja2->spacy->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->-r requirements.txt (line 5)) (2.22)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (2.19.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6)) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shyamaldasandhi\\ailab\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "     ---------------------------------------- 0.0/400.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/400.7 MB ? eta -:--:--\n",
      "      -------------------------------------- 5.2/400.7 MB 21.3 MB/s eta 0:00:19\n",
      "     --- ---------------------------------- 39.1/400.7 MB 88.8 MB/s eta 0:00:05\n",
      "     ------- ----------------------------- 82.1/400.7 MB 127.8 MB/s eta 0:00:03\n",
      "     ----------- ------------------------ 124.3/400.7 MB 147.1 MB/s eta 0:00:02\n",
      "     -------------- --------------------- 166.7/400.7 MB 159.0 MB/s eta 0:00:02\n",
      "     ------------------ ----------------- 208.4/400.7 MB 166.5 MB/s eta 0:00:02\n",
      "     ---------------------- ------------- 248.5/400.7 MB 170.9 MB/s eta 0:00:01\n",
      "     -------------------------- --------- 292.3/400.7 MB 206.9 MB/s eta 0:00:01\n",
      "     ------------------------------ ----- 336.9/400.7 MB 209.5 MB/s eta 0:00:01\n",
      "     --------------------------------- -- 377.5/400.7 MB 206.9 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     -----------------------------------  400.6/400.7 MB 207.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- 400.7/400.7 MB 32.7 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted information (no spaCy): {'name': 'Abhishek \\nDasandhi', 'email': 'shyamaldasandhi@gmail.com', 'phone': '9646920015', 'filepath': 'Abhishek Dasandhi CV.pdf'}\n",
      "Extracted information (with spaCy): {'name': 'Postman', 'email': 'shyamaldasandhi@gmail.com', 'phone': '9646920015', 'filepath': 'Abhishek Dasandhi CV.pdf'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import io  # Added for potential memory issues with large files\n",
    "import docx\n",
    "import pdfminer.high_level  # Explicit import for high-level functions\n",
    "\n",
    "# Optional: Install spaCy's English model for better name recognition.  Large model recommended.\n",
    "# python -m spacy download en_core_web_lg  # Or en_core_web_trf for transformer-based, even better\n",
    "import spacy  #  Requires: pip install spacy\n",
    "\n",
    "# Added for robustness\n",
    "from typing import List, Optional\n",
    "\n",
    "# Requires: pip install pdfminer.six python-docx spacy\n",
    "def extract_information_from_resume(resume_path: str, use_spacy: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts personal information (name, email, phone number) from a resume file (PDF or DOCX).\n",
    "\n",
    "    Args:\n",
    "        resume_path (str): The path to the resume file.\n",
    "        use_spacy (bool, optional): Whether to use spaCy for name extraction. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted information. Keys are:\n",
    "              'name', 'email', 'phone', 'filepath'.  If a piece of info is not found, its value will be None.\n",
    "    \"\"\"\n",
    "\n",
    "    extracted_data = {\n",
    "        'name': None,\n",
    "        'email': None,\n",
    "        'phone': None,\n",
    "        'filepath': resume_path\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        text = extract_text_from_resume(resume_path)\n",
    "        if text:\n",
    "            extracted_data['email'] = extract_email(text)\n",
    "            extracted_data['phone'] = extract_phone_number(text)\n",
    "\n",
    "            if use_spacy:\n",
    "                extracted_data['name'] = extract_name_spacy(text)\n",
    "            else:\n",
    "                extracted_data['name'] = extract_name_regex(text) # Fallback if spaCy not used\n",
    "        else:\n",
    "            print(f\"Warning: Could not extract text from resume at {resume_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {resume_path}: {e}\")\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_from_resume(resume_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Extracts text from a resume file (PDF or DOCX).\n",
    "\n",
    "    Args:\n",
    "        resume_path (str): The path to the resume file.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The extracted text, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if resume_path.endswith('.pdf'):\n",
    "            return extract_text_from_pdf(resume_path)\n",
    "        elif resume_path.endswith('.docx'):\n",
    "            return extract_text_from_docx(resume_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {resume_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {resume_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> Optional[str]:\n",
    "    \"\"\"Extracts text from a PDF file using pdfminer.six.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The extracted text, or None if an error occurred.  Handles potential memory issues.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            text = pdfminer.high_level.extract_text(file)\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF {pdf_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_text_from_docx(docx_path: str) -> Optional[str]:\n",
    "    \"\"\"Extracts text from a DOCX file using python-docx.\n",
    "\n",
    "    Args:\n",
    "        docx_path (str): The path to the DOCX file.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The extracted text, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = docx.Document(docx_path)\n",
    "        full_text = []\n",
    "        for paragraph in doc.paragraphs:\n",
    "            full_text.append(paragraph.text)\n",
    "        return '\\n'.join(full_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from DOCX {docx_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_name_regex(text: str) -> Optional[str]:\n",
    "    \"\"\"Extracts a name from text using regular expressions.  Simple heuristic.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to extract from.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The extracted name, or None if not found.\n",
    "    \"\"\"\n",
    "    name = None\n",
    "    name_pattern = r\"([A-Z][a-z]+)\\s+([A-Z][a-z]+)\"  # Matches \"First Last\"\n",
    "\n",
    "    match = re.search(name_pattern, text)\n",
    "    if match:\n",
    "        name = match.group()  # Return the full match\n",
    "    return name\n",
    "\n",
    "\n",
    "def extract_name_spacy(text: str) -> Optional[str]:\n",
    "    \"\"\"Extracts a name from text using spaCy's Named Entity Recognition.  Requires `spacy` and an English model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to extract from.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The extracted name, or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_lg\")  # Or a similar model\n",
    "        doc = nlp(text)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                return ent.text\n",
    "        return None  # No PERSON entity found\n",
    "    except OSError:\n",
    "        print(\"Error: spaCy model (en_core_web_lg) not found. Please download it using: python -m spacy download en_core_web_lg\")\n",
    "        return None # Or raise the exception if you want the program to stop.\n",
    "    except Exception as e:\n",
    "        print(f\"Error using spaCy for name extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_email(text: str) -> Optional[str]:\n",
    "    \"\"\"Extracts an email address from text using regular expressions.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to extract from.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The extracted email address, or None if not found.\n",
    "    \"\"\"\n",
    "    email = None\n",
    "    email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"  # More robust email regex\n",
    "    match = re.search(email_pattern, text)\n",
    "    if match:\n",
    "        email = match.group()\n",
    "    return email\n",
    "\n",
    "\n",
    "def extract_phone_number(text: str) -> Optional[str]:\n",
    "    \"\"\"Extracts a phone number from text using regular expressions.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to extract from.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The extracted phone number, or None if not found.\n",
    "    \"\"\"\n",
    "    phone = None\n",
    "    phone_pattern = r\"\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\"  # Handles various phone number formats\n",
    "    match = re.search(phone_pattern, text)\n",
    "    if match:\n",
    "        phone = match.group()\n",
    "    return phone\n",
    "\n",
    "\n",
    "def process_directory(directory_path: str, use_spacy: bool = True) -> List[dict]:\n",
    "    \"\"\"Processes all PDF and DOCX files in a directory and returns a list of extracted information.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path to the directory containing resume files.\n",
    "        use_spacy (bool, optional): Whether to use spaCy for name extraction. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries, where each dictionary contains the extracted information from a resume.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(('.pdf', '.docx')):\n",
    "            filepath = os.path.join(directory_path, filename)\n",
    "            data = extract_information_from_resume(filepath, use_spacy)\n",
    "            results.append(data)\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example usage:\n",
    "\n",
    "    # 1. Process a single resume file:\n",
    "    resume_file = \"Abhishek Dasandhi CV.pdf\"  # Replace with your file\n",
    "    '''\n",
    "    # Create a dummy PDF file for testing purposes\n",
    "    with open(resume_file, \"w\") as f:\n",
    "        f.write(\"John Doe\\njohn.doe@example.com\\n(123) 456-7890\")\n",
    "    extracted_info = extract_information_from_resume(resume_file)\n",
    "    print(\"Extracted information from single file:\", extracted_info)\n",
    "\n",
    "    # 2. Process all resumes in a directory:\n",
    "    resume_directory = \"resumes\"  # Replace with your directory. Create the directory if it doesn't exist!\n",
    "    if not os.path.exists(resume_directory):\n",
    "      os.makedirs(resume_directory) # create the directory if it doesn't exist.\n",
    "    # Create a dummy PDF file for testing purposes\n",
    "    resume_file_2 = \"resumes/example_resume2.pdf\"\n",
    "    with open(resume_file_2, \"w\") as f:\n",
    "        f.write(\"Jane Smith\\njane.smith@example.com\\n(987) 654-3210\")\n",
    "\n",
    "    extracted_info_list = process_directory(resume_directory)\n",
    "    print(\"Extracted information from directory:\")\n",
    "    for info in extracted_info_list:\n",
    "        print(info)\n",
    "    '''\n",
    "    # Example with spaCy disabled:\n",
    "    extracted_info = extract_information_from_resume(resume_file, use_spacy=False)\n",
    "    print(\"Extracted information (no spaCy):\", extracted_info)\n",
    "    extracted_info = extract_information_from_resume(resume_file, use_spacy=True)\n",
    "    print(\"Extracted information (with spaCy):\", extracted_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
